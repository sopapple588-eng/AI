import numpy as np
import matplotlib.pyplot as plt

#找到函數的最小值
def func(x): 
    return np.square(x)

def dfunc(x): 
    return 2 * x

def GD(x_start, df, epochs, lr):    
    """ 
    梯度下降法 (Gradient Descent)
    給定起始點、目標函數的一階導函數、學習率與迭代次數，
    透過反覆更新 x，逼近目標函數的最小值。
    :param x_start: x 的起始點 (初始權重)
    :param df: 目標函數的一階導函數 (梯度)
    :param epochs: 反覆運算次數
    :param lr: 學習率 (Learning Rate)
    :return: 每次更新後的 x 值 (含起始點)，長度為 epochs + 1
    """    
    xs = np.zeros(epochs + 1)  # 建立陣列紀錄每次更新後的 x 值
    x = x_start                # 設定初始值
    xs[0] = x                  # 儲存初始值
    
    for i in range(epochs):         
        dx = df(x)             # 計算目前 x 的梯度
        v = - dx * lr          # 計算更新量
        x += v                 # 更新 x
        xs[i + 1] = x          # 儲存更新後的 x 值
    
    return xs                  # 回傳x 值

x_start = 5      # 起始點 x = 5
epochs = 15      # 執行 15 次迭代
lr = 0.3        

# 執行梯度下降法，取得每次更新後的 x
x = GD(x_start, dfunc, epochs, lr=lr) 

# 印出每次更新後的 x 值
print(x)

color = 'r'    
from numpy import arange
t = arange(-6.0, 6.0, 0.01)      # 建立範圍
plt.plot(t, func(t), c='b')      # 繪製函數曲線
plt.plot(x, func(x), c=color, label='lr={}'.format(lr))  # 繪製梯度下降的路徑
plt.scatter(x, func(x), c=color)  # 標出每次更新的位置 
plt.legend()
plt.show()
